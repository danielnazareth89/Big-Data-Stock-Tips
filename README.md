# Big-Data-Stock-Tips
This is a set of projects I did where I used Apache Hadoop, Pig, Hive and HBase to efficiently compute the least volatile stocks from a dataset having as many as 
29000 tickers. All of the code was tested and benchmarked on the University at Buffalo's premier high performance cluster/datacenter called CCR(Center for Computational Research) located in downtown Buffalo and made available to students and researchers for academic purposes. The cluster has more than 170 Tflops of peak performance compute capacity and 3 PB of high performance storage, making it the ideal platform to test data intensive project work on. You can read more about CCR [here](https://www.buffalo.edu/ccr.html)
